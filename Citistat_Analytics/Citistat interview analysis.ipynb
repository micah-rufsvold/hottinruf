{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solid Waste Analysis\n",
    "## Question\n",
    "\n",
    "It is important for the City of Baltimore to provide services equitably to residents. A key performance indicator (KPI) of many city services is on time completion (completing work before the due date). Solid Waste would like to assess the performance of their services (SR Type), specifically Cleaning, Boarding, High Grass and Weeds (HGW), Dirty Streets, and Dirty Alleys. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "#This originally imported the Excel doc and saved it off as a pickle file for quick access.\n",
    "\"\"\"import pandas as pd \n",
    "original_recs = pd.read_excel(r'311_CSR_SW.xlsx')\n",
    "original_recs.to_pickle('311_CSR_SW.pkl')\n",
    "original_recs.head()\"\"\"\n",
    "\n",
    "#Functions to init\n",
    "def graph_hoods_by_overdue(df, name, sort_type='overdue'):\n",
    "    overdue_by_hood = group_hoods(df)\n",
    "    if sort_type == 'overdue':\n",
    "        sorted_overdue = sort_by_overdue(overdue_by_hood)\n",
    "        g = graph_hoods(sorted_overdue, name,\"num\",\"Neighborhoods, Ranked by % Overdue\")\n",
    "    elif sort_type == 'crime':\n",
    "        print('made it')\n",
    "        sorted_overdue = sort_by_crime(overdue_by_hood)\n",
    "        g = graph_hoods(sorted_overdue, name,\"num\",\"Neighborhoods, Ranked by Crime Total\")\n",
    "    return g\n",
    "\n",
    "def group_hoods(df):\n",
    "    neighborhood_groups = df.groupby(\"Neighborhood\")\n",
    "    overdue_by_hood = neighborhood_groups[\"Overdue\"].apply(lambda x : x.sum()/len(x)).reset_index(name=\"Percent Overdue\")\n",
    "    overdue_count = neighborhood_groups[\"Overdue\"].apply(lambda x: len(x)).reset_index(name = \"Total\")\n",
    "    overdue_by_hood[\"Total Requests\"] = overdue_count[\"Total\"]\n",
    "    return overdue_by_hood\n",
    "    \n",
    "def sort_by_overdue(df):\n",
    "    display(df)\n",
    "    sorted_overdue = df.sort_values(by=\"Percent Overdue\")\n",
    "    sorted_overdue[\"num\"] = np.arange(0,len(df))\n",
    "    sorted_overdue.drop(sorted_overdue.loc[sorted_overdue[\"Total Requests\"]<36].index,inplace=True)\n",
    "    return sorted_overdue\n",
    "\n",
    "\n",
    "def sort_by_crime(df):\n",
    "    crime_data = pd.read_csv('BPD_Part_1_Victim_Based_Crime_Data.csv')\n",
    "    crime_by_hood = crime_data.groupby('Neighborhood')\n",
    "    crime_by_hood = crime_by_hood.apply(lambda x : len(x)).reset_index(name = 'Crime Total')\n",
    "    crime_by_hood['Neighborhood']= crime_by_hood['Neighborhood'].str.lower()\n",
    "    df['Neighborhood']= df['Neighborhood'].str.lower()\n",
    "    \n",
    "    df['Crime'] = df['Neighborhood'].apply(lambda x : crime_by_hood.loc[crime_by_hood['Neighborhood'] == x]['Crime Total'])\n",
    "    display(df)\n",
    "\n",
    "def graph_hoods(df, name, xvalues, xlabel, ):\n",
    "    g = df.plot(y=\"Percent Overdue\", c=\"Total Requests\", x=xvalues, kind=\"scatter\", colormap='viridis', title=name, figsize= (5,4))\n",
    "    g.set_xlabel(xlabel, fontsize=12)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Clean Records Dataframe\n",
    "\"Please ignore any services labeled as “proactive”, or status noted as duplicate. Using the dataset “311_CSR” provided and filtering to only include work created from January 1, 2017- December 31, 2019.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "original_recs = pd.read_pickle(r\"311_CSR_SW.pkl\")\n",
    "\n",
    "non_proactive_recs = original_recs.loc[original_recs[\"SR Type\"].str.contains('Proactive')==False]\n",
    "non_duplicate_recs = non_proactive_recs.loc[non_proactive_recs[\"SR Status\"].str.contains('Duplicate')==False]\n",
    "\n",
    "Y17_19_recs = non_duplicate_recs[(non_duplicate_recs['Created Date'] > '2017-01-01 00:00:01') & (non_duplicate_recs['Created Date'] < '2019-12-31 23:59:59')]\n",
    "\n",
    "clean_recs = Y17_19_recs\n",
    "\n",
    "\n",
    "\n",
    "def fix_hoods(x):\n",
    "    match_hoods_dict = {\n",
    "    'CARE' : 'Middle East',\n",
    "    'Edgewood' : 'Allendale',\n",
    "    'Hamilton Hills' : 'Westfield',\n",
    "    'Old Goucher' : 'Barclay',\n",
    "    'Wilhelm Park' : 'Morrell Park',\n",
    "    'Wrenlane' : 'Wilson Park',\n",
    "    'York-Homeland' : 'Woodbourne-McCabe'}\n",
    "    hoods_to_fix = ['CARE', 'Edgewood','Hamilton Hills','Old Goucher','Wilhelm Park' 'Wrenlane','York-Homeland']\n",
    "    if x in hoods_to_fix:\n",
    "        return match_hoods_dict[x]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "clean_recs['Neighborhood'] = Y17_19_recs['Neighborhood'].apply(fix_hoods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "How many of each type of service requests were created each year from 2017-2019?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_groups = clean_recs.groupby(['SR Type'])\n",
    "service_groups.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What % of service requests were overdue each year? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overdue_recs = clean_recs.loc[clean_recs[\"Due Date\"] < clean_recs[\"Close Date\"]]\n",
    "len(overdue_recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did % overdue change overtime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_and_overdue = clean_recs\n",
    "recs_and_overdue[\"Overdue\"] = (clean_recs[\"Due Date\"] - clean_recs[\"Close Date\"]) < pd.Timedelta(0)\n",
    "by_complete_date_group = recs_and_overdue.groupby([recs_and_overdue[\"Created Date\"].dt.year,recs_and_overdue[\"Created Date\"].dt.month])\n",
    "\n",
    "overdue_percent = by_complete_date_group[\"Overdue\"].apply(lambda x : x.sum()/len(x))\n",
    "overdue_percent.plot(kind=\"line\", rot=45, figsize=(8,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the information calculated above and other information from the dataset, can you provide evidence to determine if service requests created in 2019 are being completed equitably across the city? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph_hoods_by_overdue(clean_recs.loc[clean_recs[\"Created Date\"].dt.year == 2019], \"Neighborhoods by Overdue Requests\")\n",
    "graph_hoods_by_overdue(clean_recs.loc[clean_recs[\"Created Date\"].dt.year == 2019], \"Neighborhoods by Overdue Requests\", sort_type='crime')\n",
    "\n",
    "#for group in service_groups:\n",
    " #   graph_hoods_by_overdue(group[1],group[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also provide any additional insights that you found while exploring the data.\n",
    "\n",
    "Query Census Data for each neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "reset_index() got an unexpected keyword argument 'name'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-18a08a498d7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_recs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclean_recs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Created Date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2019\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Neighborhood'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'blah'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Neighborhood'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Neighborhood'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: reset_index() got an unexpected keyword argument 'name'"
     ]
    }
   ],
   "source": [
    "crime_data = pd.read_csv('BPD_Part_1_Victim_Based_Crime_Data.csv')\n",
    "crime_by_hood = crime_data.groupby('Neighborhood')\n",
    "crime_by_hood = crime_by_hood.apply(lambda x : len(x)).reset_index(name = 'Crime Total')\n",
    "crime_by_hood['Neighborhood']= crime_by_hood['Neighborhood'].str.lower()\n",
    "\n",
    "groups = clean_recs.loc[clean_recs[\"Created Date\"].dt.year == 2019].groupby('Neighborhood')\n",
    "df = groups.sum().reset_index(name='blah')\n",
    "df['Neighborhood']= df['Neighborhood'].str.lower()\n",
    "\n",
    "df['Crime'] = df['Neighborhood'].apply(lambda x : crime_by_hood.loc[crime_by_hood['Neighborhood'] == x]['Crime Total'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_FIPS(hood):\n",
    "    if type(hood) == type(()):\n",
    "        lat=hood[0]\n",
    "        lon=hood[1]\n",
    "        query = \"https://geo.fcc.gov/api/census/block/find?latitude={}&longitude={}&showall=false&format=json\".format(lat,lon)\n",
    "        hood_resp = requests.get(query).json()\n",
    "        return hood_resp['Block']['FIPS']\n",
    "\n",
    "neighborhood_centers[\"FIPS Code\"] = neighborhood_centers[\"Lat and Lon\"].apply(get_FIPS)\n",
    "neighborhood_centers\n",
    "\n",
    "\n",
    "api.census.gov/data/{YEAR}/{DATASET}?get={variable}&for={geography}&key={dev_key}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}