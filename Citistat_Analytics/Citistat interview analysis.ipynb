{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pycharm-3f4033c0",
   "language": "python",
   "display_name": "PyCharm (hottinruf)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Solid Waste Analysis\n",
    "## Question\n",
    "\n",
    "It is important for the City of Baltimore to provide services equitably to residents. A key performance indicator (KPI) of many city services is on time completion (completing work before the due date). Solid Waste would like to assess the performance of their services (SR Type), specifically Cleaning, Boarding, High Grass and Weeds (HGW), Dirty Streets, and Dirty Alleys. \n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This originally imported the Excel doc and saved it off as a pickle file for quick access.\n",
    "\"\"\"import pandas as pd \n",
    "original_recs = pd.read_excel(r'311_CSR_SW.xlsx')\n",
    "original_recs.to_pickle('311_CSR_SW.pkl')\n",
    "original_recs.head()\"\"\""
   ]
  },
  {
   "source": [
    "## Initialize Clean Records Dataframe\n",
    "\"Please ignore any services labeled as “proactive”, or status noted as duplicate. Using the dataset “311_CSR” provided and filtering to only include work created from January 1, 2017- December 31, 2019.\" "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "original_recs = pd.read_pickle(r\"311_CSR_SW.pkl\")\n",
    "\n",
    "non_proactive_recs = original_recs.loc[original_recs[\"SR Type\"].str.contains('Proactive')==False]\n",
    "non_duplicate_recs = non_proactive_recs.loc[non_proactive_recs[\"SR Status\"].str.contains('Duplicate')==False]\n",
    "\n",
    "clean_recs = non_duplicate_recs[(non_duplicate_recs['Created Date'] > '2017-01-01 00:00:01') & (non_duplicate_recs['Created Date'] < '2019-12-31 23:59:59')]"
   ]
  },
  {
   "source": [
    "### Question 1\n",
    "How many of each type of service requests were created each year from 2017-2019?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "service_groups = clean_recs.groupby(['SR Type'])\n",
    "service_groups.size()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "What % of service requests were overdue each year? \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overdue_recs = clean_recs.loc[clean_recs[\"Due Date\"] < clean_recs[\"Close Date\"]]\n",
    "len(overdue_recs)"
   ]
  },
  {
   "source": [
    "How did % overdue change overtime?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_and_overdue = clean_recs\n",
    "recs_and_overdue[\"Overdue\"] = (clean_recs[\"Due Date\"] - clean_recs[\"Close Date\"]) < pd.Timedelta(0)\n",
    "by_complete_date_group = recs_and_overdue.groupby([recs_and_overdue[\"Created Date\"].dt.year,recs_and_overdue[\"Created Date\"].dt.month])\n",
    "\n",
    "overdue_percent = by_complete_date_group[\"Overdue\"].apply(lambda x : x.sum()/len(x))\n",
    "overdue_percent.plot(kind=\"line\", rot=45, figsize=(8,3))\n"
   ]
  },
  {
   "source": [
    "Using the information calculated above and other information from the dataset, can you provide evidence to determine if service requests created in 2019 are being completed equitably across the city? "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "recs_2019 = clean_recs.loc[clean_recs[\"Created Date\"].dt.year == 2019]\n",
    "\n",
    "neighborhood_groups = recs_2019.groupby(\"Neighborhood\")\n",
    "\n",
    "overdue_by_hood = neighborhood_groups[\"Overdue\"].apply(lambda x : x.sum()/len(x)).reset_index(name=\"Percent Overdue\")\n",
    "\n",
    "overdue_by_hood.sort_values(by=\"Percent Overdue\")\n",
    "overdue_by_hood[\"num\"] = np.arange(0,len(overdue_by_hood))\n",
    "overdue_by_hood.plot(y=\"Percent Overdue\",x=\"num\", kind=\"scatter\")"
   ]
  },
  {
   "source": [
    "You may also provide any additional insights that you found while exploring the data.\n",
    "\n",
    "Query Census Data for each neighborhood"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_centers = pd.DataFrame(neighborhood_groups[[\"Latitude\",\"Longitude\"]].apply(lambda x : (x[\"Latitude\"].mean(), x[\"Longitude\"].mean())))\n",
    "neighborhood_centers.columns = [\"Lat and Lon\"]\n",
    "neighborhood_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_FIPS(hood):\n",
    "    if type(hood) == type(()):\n",
    "        lat=hood[0]\n",
    "        lon=hood[1]\n",
    "        query = \"https://geo.fcc.gov/api/census/block/find?latitude={}&longitude={}&showall=false&format=json\".format(lat,lon)\n",
    "        hood_resp = requests.get(query).json()\n",
    "        return hood_resp['Block']['FIPS']\n",
    "\n",
    "neighborhood_centers[\"FIPS Code\"] = neighborhood_centers[\"Lat and Lon\"].apply(get_FIPS)\n",
    "neighborhood_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.census.gov/data/{YEAR}/{DATASET}?get={variable}&for={geography}&key={dev_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this worked\n"
     ]
    }
   ],
   "source": [
    "print(\"this worked\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}