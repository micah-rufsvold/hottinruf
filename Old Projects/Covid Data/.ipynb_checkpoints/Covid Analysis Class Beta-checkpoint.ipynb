{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Covid Data Analysis Object\n",
    "\n",
    "## Introduction\n",
    "The Covid_Data class takes data from the covid-19 api and makes it easy and fast to extract information. It has a number of methods that can pull summary data and graphs from the information provided by the API. Run Covid_Data.\\__doc__ to see methods.\n",
    "\n",
    "Once you have created an instance for the first time, it is fastest to use the .save() and load() methods, not create a full new instance each time you start up the program.\n",
    "\n",
    "### Extending the Class\n",
    "A note on the data's structure:\n",
    "\n",
    "The data are stored in two objects: a pandas dataframe with information on each unique reporting location (i.e. \"Baltimore, MD\", \"Paris, FR\") called self._loc_info and a rank 4 numpy array containing all covid records called self._covid_data. The numpy array's axes are Location, Date, Data type (\"Confirmed\", \"Deaths\", etc.), and Data (Total, percent, etc.)\n",
    "\n",
    "\n",
    "### Note on the status of this notebook\n",
    "\n",
    "This is an ongoing personal project. As it stands, a user of this notebook can use the class to pull down fresh data and build summary dataframes of global Covid Data. \n",
    "\n",
    "Outstanding goals of the project are:\n",
    "\n",
    "- Finishing the .inspect() function so that the user can specify tighter constraints on the summary dataframe\n",
    "- Develop a .disp() function that visualizes the data from an .inspect() dataframe result\n",
    "- Integrate population data to include per capita rates to the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import json, requests, datetime, itertools\n",
    "from IPython.display import clear_output, display\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "class Covid_Data:\n",
    "    \n",
    "    def __init__(self,file1='', file2=''):\n",
    "        \"\"\"Sets up new object from saved files. Or creates\n",
    "        an empty object waiting for .load().\n",
    "        \n",
    "        Attributes\n",
    "        ----------\n",
    "        File1 : string, optional\n",
    "            Can be .json, .pkl, or empty.\n",
    "            OR if 'New', class will download fresh data from the API\n",
    "        File2 : string, optional\n",
    "            Can be .npy or empty.\"\"\"\n",
    "        self._cores = mp.cpu_count()\n",
    "        #load file data\n",
    "        if file2:\n",
    "            self.load(file1,file2)\n",
    "        elif file1 == 'New':\n",
    "            print('updating')\n",
    "            self.update_data()\n",
    "        elif file1:\n",
    "            self._initial_setup(file1)\n",
    "        else:\n",
    "            print('Created empty data object.\\nRun .load(file1,file2) or .update_data() '+\n",
    "                  'to get started!') \n",
    "        #set initial filter attributes\n",
    "        self.start_date = datetime.date(2020,1,22)\n",
    "        days = datetime.timedelta(self._covid_data.shape[1])\n",
    "        self.end_date = self.start_date+days\n",
    "        self.locations = [[],[],[]]\n",
    "        self._week_data\n",
    "        self.current_period = 'Daily'\n",
    "        \n",
    "    #Housekeeping/instrumental Methods\n",
    "    def _parallelize_dataframe(self,df, func, n_cores=4):\n",
    "        #Takes dataframe operations and parallelizes them across all cpu cores.\n",
    "        df_split = np.array_split(df, n_cores)\n",
    "        pool = Pool(n_cores)\n",
    "        df = pd.concat(pool.map(func, df_split))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return df\n",
    "    def _parallelize_array(self, df, func, n_cores=4):\n",
    "        #Takes numpy array operations and parallelizes them across all cpu cores.\n",
    "        df_split1 = np.array_split(df, n_cores)\n",
    "        df_split = []\n",
    "        count = 0 \n",
    "        for arr in range(0,df_split1):\n",
    "            df_split.append([df_split1[arr],count])\n",
    "            count += df_split[arr].shape[0]\n",
    "        pool = Pool(n_cores)\n",
    "        df = np.concatenate(pool.map(func, df_split),axis=0)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        return df\n",
    "    def _update_progress(self,progress):\n",
    "        #this is a simple function that updates a loading bar\n",
    "        bar_length = 20\n",
    "        if isinstance(progress, int):\n",
    "            progress = float(progress)\n",
    "        if not isinstance(progress, float):\n",
    "            progress = 0\n",
    "        if progress < 0:\n",
    "            progress = 0\n",
    "        if progress >= 1:\n",
    "            progress = 1\n",
    "        block = int(round(bar_length * progress))\n",
    "        clear_output(wait = True)\n",
    "        text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "        print(text)\n",
    "        \n",
    "        \n",
    "    #Internal Methods\n",
    "    def _initial_setup(self, jsonfile): #takes a saved JSON file and sets up necessary data structures.\n",
    "        #Open and load JSON file\n",
    "        f = open(jsonfile)\n",
    "        data = json.load(f)\n",
    "        f.close()\n",
    "        self._update_progress(.04) #create loading bar\n",
    "        \n",
    "        #dataframe to hold JSON data\n",
    "        self._df = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        \n",
    "        #drop duplicates for each location and save location data into _loc_info\n",
    "        loc_info = self._df.drop_duplicates(subset = ['Country','Province','City'])\n",
    "        self._loc_info = loc_info[['Country','Province','City','Lat','Lon']]\n",
    "        self._update_progress(.1)\n",
    "        \n",
    "        #break df into location groups\n",
    "        loc_groups = self._df.groupby(['Country','Province','City'])\n",
    "        \n",
    "        #build array of covid data, axes: [location, dates, data_type, analysis type]\n",
    "                                           #loc_count, days since 1/22, 4, 3\n",
    "        self._covid_data = np.array([self._build_data_init(group) for group in loc_groups])\n",
    "        #WORK -- parralelize this list comprehension \n",
    "        self._update_progress(.5)\n",
    "        self._covid_data = np.moveaxis(self._covid_data,1,-1)\n",
    "        self._update_progress(1)\n",
    "        \n",
    "        \n",
    "    def _build_data_init(self,arr):\n",
    "        totals = arr[1][['Confirmed','Deaths','Recovered','Active']].to_numpy(dtype=float,copy=True)\n",
    "        return self._build_data(totals)\n",
    "    \n",
    "    def _build_data(self,totals):\n",
    "        yesterdays = np.vstack((totals[1:],np.array([0,0,0,0]))) #make a new totals shifted one day \n",
    "        deltas = np.subtract(totals,yesterdays) #find the difference between totals and yesterdays\n",
    "        with np.errstate(divide='ignore', invalid='ignore'): # find the quotient of deltas and totals, ignore divide by zero error\n",
    "            percents = np.true_divide(deltas,totals)\n",
    "            percents[percents == np.inf] = 0\n",
    "            percents = np.nan_to_num(percents)\n",
    "        num_data = np.array([totals, deltas, percents]) #create an array with rank data type, date/loc, data cat\n",
    "        return(num_data)\n",
    "\n",
    "    def _get_new_data(self):\n",
    "        #This method queries covid19api.com for new data and saves to a JSON file\n",
    "        import requests\n",
    "\n",
    "        url = \"https://api.covid19api.com/all\"\n",
    "\n",
    "        payload = {}\n",
    "        headers= {}\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers, data = payload)\n",
    "        json_data = response.json()\n",
    "            \n",
    "        #all_data = requests.get(\"https://api.covid19api.com/all\")\n",
    "        \n",
    "        save_data = json.dumps(json_data)\n",
    "        writeFile = open('covid_data.json', 'w')\n",
    "        writeFile.write(save_data)\n",
    "        writeFile.close()\n",
    "        return('covid_data.json')\n",
    "    \n",
    "    \n",
    "    #Properties\n",
    "    @property\n",
    "    def current_period(self):\n",
    "        \"\"\"The current period decides on the time granularity of the data. \n",
    "        It can be set to 'Daily' or 'Weekly' (default, 'Daily').\"\"\"\n",
    "        return self._current_period\n",
    "    @current_period.setter\n",
    "    def current_period(self, period='Daily'):\n",
    "        if period.lower() == 'daily':\n",
    "            self._current_period = 'daily'\n",
    "        elif period.lower() == 'weekly':\n",
    "            self._current_period = 'weekly'\n",
    "        else:\n",
    "            self._current_period = 'daily'\n",
    "            print('You must use \"Daily\" or \"Weekly\" to set period.')\n",
    "    @property\n",
    "    def _week_data(self):\n",
    "        #pull every loc, every 7th day, all measures and measure types\n",
    "        week_totals = self._covid_data[:,::7,:,0]\n",
    "        #array from [build_data(loc) for loc in totals]\n",
    "        self.__week_data = np.array([self._build_data(loc) for loc in week_totals], dtype=float, copy = True)\n",
    "        return self.__week_data\n",
    "    @property\n",
    "    def start_date(self):\n",
    "        \"\"\"Start date sets the earliest date of data to consider in .inspect().\n",
    "        It defaults to 1 Jan 2020. It can be set directly with a datetime.date object\n",
    "        or with the .set_start_date() method.\"\"\"\n",
    "        return self._start_date\n",
    "    @start_date.setter\n",
    "    def start_date(self,start_date):\n",
    "        beg = datetime.date(2020,1,22)\n",
    "        end = datetime.date.today()\n",
    "        if (start_date - beg).days < 0 or (end - start_date).days < 1:\n",
    "            print(\"Start date must be on or after Jan 22, 2020 and before today.\")\n",
    "        else:\n",
    "            self._start_date = start_date\n",
    "    @property\n",
    "    def end_date(self):\n",
    "        \"\"\"End date sets the latest date of data to consider in .inspect().\n",
    "        It defaults to today. It can be set directly with a datetime.date object\n",
    "        or with the .set_end_date() method.\"\"\"\n",
    "        return self._end_date\n",
    "    @end_date.setter\n",
    "    def end_date(self, end_date):\n",
    "        day_num = datetime.timedelta(self._covid_data.shape[1])\n",
    "        first = datetime.date(2020,1,22)\n",
    "        last = first + day_num\n",
    "        if (end_date - last).days >0 or (end_date - self.start_date).days< 1:\n",
    "            print('End date must come after start date and be on or before the last day in the downloaded data.'+\n",
    "                  '\\nRun .update_data to refresh data through today.')\n",
    "            self._end_date = last\n",
    "        else:\n",
    "            self._end_date = end_date\n",
    "    @property\n",
    "    def locations(self):\n",
    "        \"\"\"Filters data by country, province, and city. Use .set_locations() to\n",
    "        select filter.\"\"\"\n",
    "        return self._locations\n",
    "    @locations.setter\n",
    "    def locations(self, locations=[[],[],[]]):\n",
    "        #break locations into country, province, and city.\n",
    "        countries= locations[0]\n",
    "        provinces= locations[1]\n",
    "        cities= locations[2]\n",
    "\n",
    "        locs = self._loc_info.copy()\n",
    "        ind = pd.Series(range(0,len(locs)))\n",
    "        locs = locs.set_index(ind)\n",
    "        \n",
    "        #at each step, filter for rows that match the request\n",
    "        if len(countries):\n",
    "            locs = locs[locs['Country'].isin(countries)]\n",
    "            if len(provinces):\n",
    "                locs = locs[locs['Province'].isin(provinces)]\n",
    "                if len(cities):\n",
    "                    locs = locs[locs['City'].isin(cities)]\n",
    "        self._locations = locs\n",
    "    \n",
    "    #Methods\n",
    "    \n",
    "    def set_start_date(self, year=2020,month=1,day=22):\n",
    "        \"\"\"Easily enter start day.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        year : int, optional\n",
    "            Start year (default is 2020).\n",
    "        month : int, optional\n",
    "            Start month (default is 1).\n",
    "        day : int, optional\n",
    "            Start day (default is 22).\"\"\"\n",
    "        self.start_date = datetime.date(year,month,day)\n",
    "    def set_end_date(self, year, month, day):\n",
    "        \"\"\"Easily enter end day.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        year : int, required\n",
    "            End year.\n",
    "        month : int, required\n",
    "            End month.\n",
    "        day : int, required\n",
    "            End day.\"\"\"\n",
    "        if month and day:\n",
    "            self.end_time = datetime.date(year,month,day)\n",
    "        else:\n",
    "            self.end_time = datetime.date.today()\n",
    "\n",
    "    def inspect(self, groupby = 'All', data_measure=['Confirmed','Deaths','Recovered','Active'], \n",
    "                measure_type=['Total','Change In', 'Percent'], period=None, \n",
    "                start_date = None, end_date = None, \n",
    "                locations = None):\n",
    "        \n",
    "        \"\"\"Inspect uses the class filter attributes, some \n",
    "        other filters, and some other variables to return a \n",
    "        dataframe of specific Covid-19. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        groupby : str, optional\n",
    "            Returns summary data by given group (options \n",
    "            are 'None', 'City', 'Province', 'Country', or '\n",
    "            Dates', default is 'None').\n",
    "        data_measure: list, optional\n",
    "           List of data measures to include. By default, it \n",
    "           includes all options: ['Confirmed', 'Deaths', \n",
    "           'Recovered', 'Active']. \n",
    "        measure_type\n",
    "            List of types of each measure to include. By \n",
    "            default, it includes all options: ['Total', \n",
    "            'Change In', 'Percent'], \n",
    "        period : str, optional\n",
    "            Choose 'weekly' or 'daily' data (default is \n",
    "            self.current_period).\n",
    "        start_date : datetime.date object, optional\n",
    "            Set start date of data (default is self.start_data).\n",
    "        end_date : datetime.date object, optional\n",
    "            Set end date of data (default is self.end_date).\n",
    "        locations: list, optional\n",
    "            Enter list of length three containing lists of \n",
    "            countries, provinces, and cities to filter by. \n",
    "            It is recommend to use .set_locations() instead \n",
    "            of entering locations manually (default is self.locations).\n",
    "            \"\"\" \n",
    "        if period is None:\n",
    "            period=self.current_period\n",
    "        if start_date is None:\n",
    "            start_date = self.start_date\n",
    "        if end_date is None:\n",
    "            end_date = self.end_date\n",
    "        if locations is None:\n",
    "            locations = self.locations\n",
    "        if period.lower() == 'weekly':\n",
    "            inspect_arr = self._week_data\n",
    "        else:\n",
    "            inspect_arr = self._covid_data\n",
    "        #get indices of locations, filter the inspect_arr by location\n",
    "        loc_indices = self.locations.index.values.tolist()\n",
    "        #get the count for start and end date, filter axis 2 (dates)\n",
    "        start = (self.start_date - datetime.date(2020,1,22)).days\n",
    "        end = (self.end_date - datetime.date(2020,1,22)).days\n",
    "        #get the type of data measure, and match to indices\n",
    "        measures = []\n",
    "        measure_names = []\n",
    "        for meas in data_measure:\n",
    "            if meas == 'Confirmed':\n",
    "                measures.append(0)\n",
    "                measure_names.append(meas)\n",
    "            elif meas == 'Deaths':\n",
    "                measures.append(1)\n",
    "                measure_names.append(meas)\n",
    "            elif meas == 'Recovered':\n",
    "                measures.append(2)\n",
    "                measure_names.append(meas)\n",
    "            elif meas == 'Active':\n",
    "                measures.append(3)\n",
    "                measure_names.append(meas)\n",
    "        \n",
    "        #get type of measure and match to indices\n",
    "        types = []\n",
    "        type_names = []\n",
    "        for typ in measure_type:\n",
    "            if typ == 'Total':\n",
    "                types.append(0)\n",
    "                type_names.append(typ)\n",
    "            elif typ == 'Change In':\n",
    "                types.append(1)\n",
    "                type_names.append(typ)\n",
    "            elif typ == 'Percent':\n",
    "                types.append(2)\n",
    "                type_names.append(typ)\n",
    "        inspect_arr = inspect_arr[loc_indices]\n",
    "        inspect_arr = inspect_arr[:,start:end,:,:]\n",
    "        inspect_arr = inspect_arr[:,:,measures,:]\n",
    "        inspect_arr = inspect_arr[:,:,:,types]\n",
    "        self._current_arr = inspect_arr\n",
    "        ##BUILD Dataframe\n",
    "        if groupby == 'All':\n",
    "            #get number of time entries (days or weeks)\n",
    "            loc_ents, time_ents, measures, types = self._current_arr.shape\n",
    "            #vstack first axis of array\n",
    "            concat_locs = self._current_arr.reshape(loc_ents*time_ents, measures, types)\n",
    "            loc_count = concat_locs.shape[0]\n",
    "            #hstack last axis of array\n",
    "            concat_locs = np.moveaxis(concat_locs, 0,-1)\n",
    "            formatted = concat_locs.reshape(measures*types,loc_count)\n",
    "            formatted = np.moveaxis(formatted,0,-1)\n",
    "            #make it a dataframe\n",
    "            columns = [x[0]+' '+x[1] for x in list(itertools.product(measure_names, type_names))]\n",
    "            df = pd.DataFrame(formatted, columns=columns)\n",
    "            sep = np.array_split(df, len(self.locations))\n",
    "\n",
    "            #function that adds loc data to sep DFs, vectorize, run\n",
    "            #add_locs = np.vectorize(self.add_locs)\n",
    "            locationsnow = self.locations\n",
    "            locationsnow = locationsnow.set_index(np.arange(0,len(locationsnow)))\n",
    "            all_dfs = self.add_locs(sep, locationsnow)\n",
    "            self._current_df = pd.concat(all_dfs)\n",
    "            return self._current_df\n",
    "    \n",
    "    def add_locs(self,dfs_arr, loc_info):\n",
    "        for index, df in enumerate(dfs_arr):\n",
    "            df['Country'] = loc_info['Country'].iloc[index]\n",
    "            df['Province'] = loc_info['Province'].iloc[index]\n",
    "            df['City'] = loc_info['City'].iloc[index]\n",
    "            df['Lat'] = loc_info['Lat'].iloc[index]\n",
    "            df['Lon'] = loc_info['Lon'].iloc[index]\n",
    "            df['Date'] = self.start_date + datetime.timedelta(index)\n",
    "        return dfs_arr\n",
    "    \n",
    "    def set_locations(self):\n",
    "        print(\"\"\"This process will filter Covid Data by entering \n",
    "countries, provinces, and cities of interest.\n",
    "We'll start by entering countries. \n",
    "        \n",
    "        \"\"\")\n",
    "        #setup categories for string formatting\n",
    "        cats = [('country', 'countries'), ('province', 'provinces'), ('city','cities')]\n",
    "        loc_collect = [[],[],[]]\n",
    "        for index, cat in enumerate(cats):\n",
    "            sing = cat[0]\n",
    "            plur = cat[1]\n",
    "            \n",
    "            #start with all locations, then filter based on user's previous entries.\n",
    "            if index == 0:\n",
    "                cur_locs = self._loc_info\n",
    "            else:\n",
    "                cur_locs = cur_locs.loc[cur_locs[cats[index-1][0].capitalize()].isin(loc_collect[index-1])]\n",
    "             \n",
    "            #make a list of the current location optics, variable for user response, and response collector\n",
    "            all_list = cur_locs[sing.capitalize()].unique().tolist()\n",
    "            response = ''\n",
    "            loc_filter = []\n",
    "            #format massages to user\n",
    "            error = \"\"\"That did not match a {} in the location list.\n",
    "            Please enter a country, 'All', 'list [search string]', 'help', or 'done'.\"\"\".format(sing)\n",
    "            \n",
    "            instructions = \"\"\"\n",
    "Let's enter {} of interest.\n",
    "\n",
    "You can enter 'list' to see all {}. \n",
    "If you add a space and a string after 'list', I'll return any \n",
    "{} whose name contains that string.\n",
    "\n",
    "Type in a {} name and hit enter, and I'll add it to our filter.\n",
    "\n",
    "If you enter 'All', I'll add all {} to the filter.\n",
    "\n",
    "Type in 'Done' and I'll move forward.\"\"\".format(plur,plur,sing,sing,plur)\n",
    "            \n",
    "            print(instructions)\n",
    "            \n",
    "            #loop on location request \n",
    "            while not response.lower() == 'done':\n",
    "                response = input(\"Enter a {} (enter 'help' for instructions) \".format(sing))\n",
    "                if response[0:4].lower() == 'list':\n",
    "                    if len(response) > 5:\n",
    "                        search = response[5:].lower()\n",
    "                        matches = [loc for loc in all_list if search in loc.lower()]\n",
    "                        print(matches)\n",
    "                    else:\n",
    "                        print(all_list)\n",
    "                elif response.lower() == 'help':\n",
    "                    print(instructions)\n",
    "                elif response.lower() == 'exit':\n",
    "                    return\n",
    "                elif response.lower() == 'done':\n",
    "                    pass\n",
    "                elif response.lower() == 'all':\n",
    "                    loc_collect[index] = all_list\n",
    "                    response = 'done'\n",
    "                elif response in all_list:\n",
    "                    loc_collect[index].append(response)\n",
    "                else:\n",
    "                    print(error)\n",
    "        #if the user entered no locations, add all locations\n",
    "        if not loc_collect[index]:\n",
    "            loc_collect[index] = all_list\n",
    "            \n",
    "        self.locations = loc_collect\n",
    "        \n",
    "    def update_data(self):\n",
    "        \"\"\"Get fresh pull from covid19api, update JSON file, update live data object\"\"\"\n",
    "        proceed = input('This will download 10MB of data and should be used infrequently. '+\n",
    "                       '\\nAre you sure you want to proceed? (Y/N) : ')\n",
    "        if proceed in ['y','Y','Yes','yes']:\n",
    "            print('This will take some time.')\n",
    "            file = self._get_new_data()\n",
    "            self._initial_setup(file)\n",
    "    def save(self):\n",
    "        \"\"\"Save current covid data into two files for quick access next time.\"\"\"\n",
    "        self._loc_info.to_pickle('location_info.pkl')\n",
    "        np.save('covid_data.npy',self._covid_data)\n",
    "    def load(self, file1, file2):\n",
    "        \"\"\"Load data from saved session for quick access\n",
    "        Parameters\n",
    "        ----------\n",
    "        file1 : str , file name for the .pkl data\n",
    "        file2 : str , file name for the .npy data\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        NameError\n",
    "            Wrong file type given for file1 or file2\"\"\"\n",
    "        if file1[-3:] == 'pkl' and file2[-3:] == 'npy':\n",
    "            self._loc_info = pd.read_pickle(file1)\n",
    "            self._covid_data = np.load(file2)\n",
    "        else:\n",
    "            raise NameError('File1 must be .pkl and File2 must be .npy')\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following line will pull down new covid data. However, the API was having timeout issues when I tested today.\n",
    "#It may or may not work\n",
    "\n",
    "#covid = Covid_Data('New')\n",
    "\n",
    "#This uses the .json file I download previously. It is missing the last several weeks of data.\n",
    "covid = Covid_Data(\"covid_data.json\")\n",
    "covid.locations=[['United States of America'],['Maryland'],[]]\n",
    "\n",
    "#You can use the following method to select specific locations you'd like to inspect\n",
    "#covid.set_locations()\n",
    "\n",
    "covid.set_start_date(2020,4,1)\n",
    "covid.set_end_date(2020,4,30)\n",
    "df = covid.inspect()\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
